{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®€å–è³‡æ–™\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry\\AppData\\Local\\Temp\\ipykernel_6672\\3841042699.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train[col] = train[col].fillna(train[col].mode()[0])\n",
      "C:\\Users\\Henry\\AppData\\Local\\Temp\\ipykernel_6672\\3841042699.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test[col] = test[col].fillna(test[col].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "# è™•ç†ç¼ºå¤±å€¼ï¼šæ•¸å€¼æ¬„ä½\n",
    "num_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in num_cols:\n",
    "    train[col] = train[col].fillna(train[col].median())\n",
    "    test[col] = test[col].fillna(test[col].median())\n",
    "\n",
    "# è™•ç†ç¼ºå¤±å€¼ï¼šé¡åˆ¥æ¬„ä½\n",
    "cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].fillna(train[col].mode()[0])\n",
    "    test[col] = test[col].fillna(test[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‹†åˆ† Cabin\n",
    "train['Deck'] = train['Cabin'].str.split('/').str[0]\n",
    "train['Num'] = train['Cabin'].str.split('/').str[1]\n",
    "train['Side'] = train['Cabin'].str.split('/').str[2]\n",
    "\n",
    "test['Deck'] = test['Cabin'].str.split('/').str[0]\n",
    "test['Num'] = test['Cabin'].str.split('/').str[1]\n",
    "test['Side'] = test['Cabin'].str.split('/').str[2]\n",
    "\n",
    "# å¡«è£œ Cabin ç¼ºå¤±å€¼\n",
    "train[['Deck', 'Num', 'Side']] = train[['Deck', 'Num', 'Side']].fillna(train[['Deck', 'Num', 'Side']].mode().iloc[0])\n",
    "test[['Deck', 'Num', 'Side']] = test[['Deck', 'Num', 'Side']].fillna(test[['Deck', 'Num', 'Side']].mode().iloc[0])\n",
    "\n",
    "# è½‰æ› Num ç‚ºæ•¸å€¼\n",
    "train['Num'] = pd.to_numeric(train['Num'], errors='coerce').fillna(0).astype(int)\n",
    "test['Num'] = pd.to_numeric(test['Num'], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç·¨ç¢¼é¡åˆ¥æ¬„ä½\n",
    "cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾µå·¥ç¨‹ï¼šç¸½æ¶ˆè²»\n",
    "train['TotalSpend'] = train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "test['TotalSpend'] = test[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰¹å¾µæ•¸é‡: 14\n",
      "ç‰¹å¾µåˆ—è¡¨: ['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Deck', 'Num', 'Side', 'TotalSpend']\n"
     ]
    }
   ],
   "source": [
    "# æº–å‚™è³‡æ–™\n",
    "X = train.drop(['PassengerId', 'Transported', 'Cabin', 'Name'], axis=1)\n",
    "y = train['Transported']\n",
    "X_test = test.drop(['PassengerId', 'Cabin', 'Name'], axis=1)\n",
    "\n",
    "print(f\"ç‰¹å¾µæ•¸é‡: {X.shape[1]}\")\n",
    "print(f\"ç‰¹å¾µåˆ—è¡¨: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†å‰²è³‡æ–™\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ç‰ˆæœ¬1: åŸå§‹LightGBMï¼ˆé»˜èªåƒæ•¸ï¼‰\n",
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1883\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "é©—è­‰æº–ç¢ºç‡: 0.8091\n"
     ]
    }
   ],
   "source": [
    "# ç‰ˆæœ¬1: ä½ çš„åŸå§‹ç‰ˆæœ¬ï¼ˆé»˜èªåƒæ•¸ï¼‰\n",
    "print(\"ğŸš€ ç‰ˆæœ¬1: åŸå§‹LightGBMï¼ˆé»˜èªåƒæ•¸ï¼‰\")\n",
    "model1 = LGBMClassifier(random_state=42)\n",
    "model1.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          callbacks=[])\n",
    "\n",
    "pred1 = model1.predict(X_val)\n",
    "score1 = accuracy_score(y_val, pred1)\n",
    "models['Original'] = model1\n",
    "scores['Original'] = score1\n",
    "print(f\"é©—è­‰æº–ç¢ºç‡: {score1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ç‰ˆæœ¬2: èª¿æ•´early stopping\n",
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1883\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "é©—è­‰æº–ç¢ºç‡: 0.8091\n"
     ]
    }
   ],
   "source": [
    "# ç‰ˆæœ¬2: ç¨å¾®èª¿æ•´early stopping\n",
    "print(\"\\nğŸš€ ç‰ˆæœ¬2: èª¿æ•´early stopping\")\n",
    "model2 = LGBMClassifier(random_state=42)\n",
    "model2.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          callbacks=[])\n",
    "\n",
    "pred2 = model2.predict(X_val)\n",
    "score2 = accuracy_score(y_val, pred2)\n",
    "models['EarlyStopping'] = model2\n",
    "scores['EarlyStopping'] = score2\n",
    "print(f\"é©—è­‰æº–ç¢ºç‡: {score2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ç‰ˆæœ¬3: ä¸åŒéš¨æ©Ÿç¨®å­\n",
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1883\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "é©—è­‰æº–ç¢ºç‡: 0.8091\n"
     ]
    }
   ],
   "source": [
    "# ç‰ˆæœ¬3: ä¸åŒéš¨æ©Ÿç¨®å­\n",
    "print(\"\\nğŸš€ ç‰ˆæœ¬3: ä¸åŒéš¨æ©Ÿç¨®å­\")\n",
    "model3 = LGBMClassifier(random_state=2024)\n",
    "model3.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          callbacks=[])\n",
    "\n",
    "pred3 = model3.predict(X_val)\n",
    "score3 = accuracy_score(y_val, pred3)\n",
    "models['DiffSeed'] = model3\n",
    "scores['DiffSeed'] = score3\n",
    "print(f\"é©—è­‰æº–ç¢ºç‡: {score3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ç‰ˆæœ¬4: è¼•å¾®èª¿åƒ\n",
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1883\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "é©—è­‰æº–ç¢ºç‡: 0.8079\n"
     ]
    }
   ],
   "source": [
    "# ç‰ˆæœ¬4: è¼•å¾®èª¿åƒï¼ˆä¿æŒç°¡å–®ï¼‰\n",
    "print(\"\\nğŸš€ ç‰ˆæœ¬4: è¼•å¾®èª¿åƒ\")\n",
    "model4 = LGBMClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=150,  # ç¨å¾®å¤šä¸€é»\n",
    "    learning_rate=0.08  # ç¨å¾®æ…¢ä¸€é»å­¸ç¿’\n",
    ")\n",
    "model4.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          callbacks=[])\n",
    "\n",
    "pred4 = model4.predict(X_val)\n",
    "score4 = accuracy_score(y_val, pred4)\n",
    "models['Tuned'] = model4\n",
    "scores['Tuned'] = score4\n",
    "print(f\"é©—è­‰æº–ç¢ºç‡: {score4:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† æœ€ä½³å–®ä¸€æ¨¡å‹: Original (0.8091)\n",
      "\n",
      "ğŸ¤ å˜—è©¦ç°¡å–®ensemble...\n",
      "Ensembleé©—è­‰æº–ç¢ºç‡: 0.8091\n",
      "ä½¿ç”¨æ¨¡å‹: ['Original', 'EarlyStopping', 'DiffSeed']\n"
     ]
    }
   ],
   "source": [
    "# é¸æ“‡æœ€ä½³å–®ä¸€æ¨¡å‹\n",
    "best_single = max(scores, key=scores.get)\n",
    "print(f\"\\nğŸ† æœ€ä½³å–®ä¸€æ¨¡å‹: {best_single} ({scores[best_single]:.4f})\")\n",
    "\n",
    "# ç°¡å–®ensemble: å¹³å‡å‰3å€‹æœ€å¥½çš„æ¨¡å‹\n",
    "print(\"\\nğŸ¤ å˜—è©¦ç°¡å–®ensemble...\")\n",
    "sorted_models = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "top3_names = [name for name, _ in sorted_models[:3]]\n",
    "\n",
    "# è¨ˆç®—ensembleé æ¸¬\n",
    "ensemble_probs = np.zeros(len(X_val))\n",
    "for name in top3_names:\n",
    "    probs = models[name].predict_proba(X_val)[:, 1]\n",
    "    ensemble_probs += probs\n",
    "ensemble_probs /= len(top3_names)\n",
    "\n",
    "ensemble_pred = (ensemble_probs > 0.5).astype(int)\n",
    "ensemble_score = accuracy_score(y_val, ensemble_pred)\n",
    "print(f\"Ensembleé©—è­‰æº–ç¢ºç‡: {ensemble_score:.4f}\")\n",
    "print(f\"ä½¿ç”¨æ¨¡å‹: {top3_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ä½¿ç”¨å–®ä¸€æ¨¡å‹ Original\n",
      "\n",
      "ğŸ¯ ç”Ÿæˆæœ€çµ‚é æ¸¬...\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n"
     ]
    }
   ],
   "source": [
    "# æ±ºå®šæœ€çµ‚æ¨¡å‹\n",
    "if ensemble_score > scores[best_single]:\n",
    "    print(f\"\\nâœ… ä½¿ç”¨Ensemble (æå‡ {ensemble_score - scores[best_single]:.4f})\")\n",
    "    use_ensemble = True\n",
    "    final_score = ensemble_score\n",
    "else:\n",
    "    print(f\"\\nâœ… ä½¿ç”¨å–®ä¸€æ¨¡å‹ {best_single}\")\n",
    "    use_ensemble = False\n",
    "    final_score = scores[best_single]\n",
    "\n",
    "# ç”Ÿæˆæœ€çµ‚é æ¸¬\n",
    "print(f\"\\nğŸ¯ ç”Ÿæˆæœ€çµ‚é æ¸¬...\")\n",
    "\n",
    "if use_ensemble:\n",
    "    # Ensembleé æ¸¬\n",
    "    final_probs = np.zeros(len(X_test))\n",
    "    for name in top3_names:\n",
    "        # ç”¨å…¨éƒ¨è³‡æ–™é‡æ–°è¨“ç·´\n",
    "        models[name].fit(X, y)\n",
    "        probs = models[name].predict_proba(X_test)[:, 1]\n",
    "        final_probs += probs\n",
    "    final_probs /= len(top3_names)\n",
    "    final_predictions = (final_probs > 0.5).astype(int)\n",
    "    filename = 'submission_ensemble.csv'\n",
    "else:\n",
    "    # å–®ä¸€æ¨¡å‹é æ¸¬\n",
    "    final_model = models[best_single]\n",
    "    final_model.fit(X, y)\n",
    "    final_predictions = final_model.predict(X_test)\n",
    "    filename = f'submission_{best_single.lower()}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "åŸºæ–¼ä½ çš„0.807æˆåŠŸç‰ˆæœ¬çš„æ”¹é€²çµæœ\n",
      "============================================================\n",
      "æ‰€æœ‰æ¨¡å‹åˆ†æ•¸:\n",
      "  Original: 0.8091\n",
      "  EarlyStopping: 0.8091\n",
      "  DiffSeed: 0.8091\n",
      "  Tuned: 0.8079\n",
      "Ensemble: 0.8091\n",
      "\n",
      "æœ€çµ‚é¸æ“‡: Original\n",
      "æœ€çµ‚åˆ†æ•¸: 0.8091\n",
      "é æ¸¬ True æ¯”ä¾‹: 0.520\n",
      "ä¿å­˜æ–‡ä»¶: submission_original.csv\n",
      "============================================================\n",
      "æœŸæœ›: åŸºæ–¼ä½ çš„æˆåŠŸåŸºç¤ï¼Œå¯èƒ½æå‡åˆ° 0.81+\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# å‰µå»ºsubmission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Transported': final_predictions\n",
    "})\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "# çµæœç¸½çµ\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"åŸºæ–¼ä½ çš„0.807æˆåŠŸç‰ˆæœ¬çš„æ”¹é€²çµæœ\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"æ‰€æœ‰æ¨¡å‹åˆ†æ•¸:\")\n",
    "for name, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {name}: {score:.4f}\")\n",
    "print(f\"Ensemble: {ensemble_score:.4f}\")\n",
    "print(f\"\")\n",
    "print(f\"æœ€çµ‚é¸æ“‡: {'Ensemble' if use_ensemble else best_single}\")\n",
    "print(f\"æœ€çµ‚åˆ†æ•¸: {final_score:.4f}\")\n",
    "print(f\"é æ¸¬ True æ¯”ä¾‹: {final_predictions.mean():.3f}\")\n",
    "print(f\"ä¿å­˜æ–‡ä»¶: {filename}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"æœŸæœ›: åŸºæ–¼ä½ çš„æˆåŠŸåŸºç¤ï¼Œå¯èƒ½æå‡åˆ° 0.81+\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
