{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry\\AppData\\Local\\Temp\\ipykernel_6672\\3841042699.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train[col] = train[col].fillna(train[col].mode()[0])\n",
      "C:\\Users\\Henry\\AppData\\Local\\Temp\\ipykernel_6672\\3841042699.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test[col] = test[col].fillna(test[col].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "# 處理缺失值：數值欄位\n",
    "num_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in num_cols:\n",
    "    train[col] = train[col].fillna(train[col].median())\n",
    "    test[col] = test[col].fillna(test[col].median())\n",
    "\n",
    "# 處理缺失值：類別欄位\n",
    "cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].fillna(train[col].mode()[0])\n",
    "    test[col] = test[col].fillna(test[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分 Cabin\n",
    "train['Deck'] = train['Cabin'].str.split('/').str[0]\n",
    "train['Num'] = train['Cabin'].str.split('/').str[1]\n",
    "train['Side'] = train['Cabin'].str.split('/').str[2]\n",
    "\n",
    "test['Deck'] = test['Cabin'].str.split('/').str[0]\n",
    "test['Num'] = test['Cabin'].str.split('/').str[1]\n",
    "test['Side'] = test['Cabin'].str.split('/').str[2]\n",
    "\n",
    "# 填補 Cabin 缺失值\n",
    "train[['Deck', 'Num', 'Side']] = train[['Deck', 'Num', 'Side']].fillna(train[['Deck', 'Num', 'Side']].mode().iloc[0])\n",
    "test[['Deck', 'Num', 'Side']] = test[['Deck', 'Num', 'Side']].fillna(test[['Deck', 'Num', 'Side']].mode().iloc[0])\n",
    "\n",
    "# 轉換 Num 為數值\n",
    "train['Num'] = pd.to_numeric(train['Num'], errors='coerce').fillna(0).astype(int)\n",
    "test['Num'] = pd.to_numeric(test['Num'], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼類別欄位\n",
    "cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵工程：總消費\n",
    "train['TotalSpend'] = train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "test['TotalSpend'] = test[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徵數量: 14\n",
      "特徵列表: ['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Deck', 'Num', 'Side', 'TotalSpend']\n"
     ]
    }
   ],
   "source": [
    "# 準備資料\n",
    "X = train.drop(['PassengerId', 'Transported', 'Cabin', 'Name'], axis=1)\n",
    "y = train['Transported']\n",
    "X_test = test.drop(['PassengerId', 'Cabin', 'Name'], axis=1)\n",
    "\n",
    "print(f\"特徵數量: {X.shape[1]}\")\n",
    "print(f\"特徵列表: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割資料\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 版本1: 原始LightGBM（默認參數）\n",
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1883\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "驗證準確率: 0.8091\n"
     ]
    }
   ],
   "source": [
    "# 版本1: 你的原始版本（默認參數）\n",
    "print(\"🚀 版本1: 原始LightGBM（默認參數）\")\n",
    "model1 = LGBMClassifier(random_state=42)\n",
    "model1.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          callbacks=[])\n",
    "\n",
    "pred1 = model1.predict(X_val)\n",
    "score1 = accuracy_score(y_val, pred1)\n",
    "models['Original'] = model1\n",
    "scores['Original'] = score1\n",
    "print(f\"驗證準確率: {score1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 版本2: 調整early stopping\n",
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1883\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "驗證準確率: 0.8091\n"
     ]
    }
   ],
   "source": [
    "# 版本2: 稍微調整early stopping\n",
    "print(\"\\n🚀 版本2: 調整early stopping\")\n",
    "model2 = LGBMClassifier(random_state=42)\n",
    "model2.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          callbacks=[])\n",
    "\n",
    "pred2 = model2.predict(X_val)\n",
    "score2 = accuracy_score(y_val, pred2)\n",
    "models['EarlyStopping'] = model2\n",
    "scores['EarlyStopping'] = score2\n",
    "print(f\"驗證準確率: {score2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 版本3: 不同隨機種子\n",
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1883\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "驗證準確率: 0.8091\n"
     ]
    }
   ],
   "source": [
    "# 版本3: 不同隨機種子\n",
    "print(\"\\n🚀 版本3: 不同隨機種子\")\n",
    "model3 = LGBMClassifier(random_state=2024)\n",
    "model3.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          callbacks=[])\n",
    "\n",
    "pred3 = model3.predict(X_val)\n",
    "score3 = accuracy_score(y_val, pred3)\n",
    "models['DiffSeed'] = model3\n",
    "scores['DiffSeed'] = score3\n",
    "print(f\"驗證準確率: {score3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 版本4: 輕微調參\n",
      "[LightGBM] [Info] Number of positive: 3500, number of negative: 3454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1883\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503307 -> initscore=0.013230\n",
      "[LightGBM] [Info] Start training from score 0.013230\n",
      "驗證準確率: 0.8079\n"
     ]
    }
   ],
   "source": [
    "# 版本4: 輕微調參（保持簡單）\n",
    "print(\"\\n🚀 版本4: 輕微調參\")\n",
    "model4 = LGBMClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=150,  # 稍微多一點\n",
    "    learning_rate=0.08  # 稍微慢一點學習\n",
    ")\n",
    "model4.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          callbacks=[])\n",
    "\n",
    "pred4 = model4.predict(X_val)\n",
    "score4 = accuracy_score(y_val, pred4)\n",
    "models['Tuned'] = model4\n",
    "scores['Tuned'] = score4\n",
    "print(f\"驗證準確率: {score4:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 最佳單一模型: Original (0.8091)\n",
      "\n",
      "🤝 嘗試簡單ensemble...\n",
      "Ensemble驗證準確率: 0.8091\n",
      "使用模型: ['Original', 'EarlyStopping', 'DiffSeed']\n"
     ]
    }
   ],
   "source": [
    "# 選擇最佳單一模型\n",
    "best_single = max(scores, key=scores.get)\n",
    "print(f\"\\n🏆 最佳單一模型: {best_single} ({scores[best_single]:.4f})\")\n",
    "\n",
    "# 簡單ensemble: 平均前3個最好的模型\n",
    "print(\"\\n🤝 嘗試簡單ensemble...\")\n",
    "sorted_models = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "top3_names = [name for name, _ in sorted_models[:3]]\n",
    "\n",
    "# 計算ensemble預測\n",
    "ensemble_probs = np.zeros(len(X_val))\n",
    "for name in top3_names:\n",
    "    probs = models[name].predict_proba(X_val)[:, 1]\n",
    "    ensemble_probs += probs\n",
    "ensemble_probs /= len(top3_names)\n",
    "\n",
    "ensemble_pred = (ensemble_probs > 0.5).astype(int)\n",
    "ensemble_score = accuracy_score(y_val, ensemble_pred)\n",
    "print(f\"Ensemble驗證準確率: {ensemble_score:.4f}\")\n",
    "print(f\"使用模型: {top3_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 使用單一模型 Original\n",
      "\n",
      "🎯 生成最終預測...\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n"
     ]
    }
   ],
   "source": [
    "# 決定最終模型\n",
    "if ensemble_score > scores[best_single]:\n",
    "    print(f\"\\n✅ 使用Ensemble (提升 {ensemble_score - scores[best_single]:.4f})\")\n",
    "    use_ensemble = True\n",
    "    final_score = ensemble_score\n",
    "else:\n",
    "    print(f\"\\n✅ 使用單一模型 {best_single}\")\n",
    "    use_ensemble = False\n",
    "    final_score = scores[best_single]\n",
    "\n",
    "# 生成最終預測\n",
    "print(f\"\\n🎯 生成最終預測...\")\n",
    "\n",
    "if use_ensemble:\n",
    "    # Ensemble預測\n",
    "    final_probs = np.zeros(len(X_test))\n",
    "    for name in top3_names:\n",
    "        # 用全部資料重新訓練\n",
    "        models[name].fit(X, y)\n",
    "        probs = models[name].predict_proba(X_test)[:, 1]\n",
    "        final_probs += probs\n",
    "    final_probs /= len(top3_names)\n",
    "    final_predictions = (final_probs > 0.5).astype(int)\n",
    "    filename = 'submission_ensemble.csv'\n",
    "else:\n",
    "    # 單一模型預測\n",
    "    final_model = models[best_single]\n",
    "    final_model.fit(X, y)\n",
    "    final_predictions = final_model.predict(X_test)\n",
    "    filename = f'submission_{best_single.lower()}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "基於你的0.807成功版本的改進結果\n",
      "============================================================\n",
      "所有模型分數:\n",
      "  Original: 0.8091\n",
      "  EarlyStopping: 0.8091\n",
      "  DiffSeed: 0.8091\n",
      "  Tuned: 0.8079\n",
      "Ensemble: 0.8091\n",
      "\n",
      "最終選擇: Original\n",
      "最終分數: 0.8091\n",
      "預測 True 比例: 0.520\n",
      "保存文件: submission_original.csv\n",
      "============================================================\n",
      "期望: 基於你的成功基礎，可能提升到 0.81+\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 創建submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Transported': final_predictions\n",
    "})\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "# 結果總結\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"基於你的0.807成功版本的改進結果\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"所有模型分數:\")\n",
    "for name, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {name}: {score:.4f}\")\n",
    "print(f\"Ensemble: {ensemble_score:.4f}\")\n",
    "print(f\"\")\n",
    "print(f\"最終選擇: {'Ensemble' if use_ensemble else best_single}\")\n",
    "print(f\"最終分數: {final_score:.4f}\")\n",
    "print(f\"預測 True 比例: {final_predictions.mean():.3f}\")\n",
    "print(f\"保存文件: {filename}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"期望: 基於你的成功基礎，可能提升到 0.81+\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
